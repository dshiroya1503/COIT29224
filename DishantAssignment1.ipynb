{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ce196c-85f6-49dc-b0fd-92ab25e3ce71",
   "metadata": {},
   "source": [
    "Section\tA:\tProblem\tStatement\tâ€“\tEnhancing\tNeural\tNetwork\tPerformance\twith\tParticle\tSwarm\tOptimization\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8dd828c-e11a-4544-bafc-eb9e42e11537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyswarm in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarm) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Download and Load Dataset\n",
    "\n",
    "# Step 1: Install required libraries\n",
    "!pip install pyswarm\n",
    "\n",
    "# Step 2: Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from pyswarm import pso  # Particle Swarm Optimization\n",
    "\n",
    "# Step 3: Load dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Step 4: Preprocess dataset\n",
    "X = data.drop('quality', axis=1).values\n",
    "y = data['quality'].values\n",
    "y = (y >= 6).astype(int)  # Convert to binary classification: good (1) vs bad (0)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46b6f6f-5871-412a-a8a0-f1f5f13322ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual NN Accuracy: 0.7406\n"
     ]
    }
   ],
   "source": [
    "# Traditional Neural Network with Manual Tuning\n",
    "\n",
    "# Build basic NN\n",
    "def build_nn_model(input_dim, hidden_units=16, learning_rate=0.01):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, input_dim=input_dim, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate\n",
    "model = build_nn_model(X_train.shape[1], hidden_units=32)\n",
    "history = model.fit(X_train, y_train, epochs=20, verbose=0, batch_size=32)\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Manual NN Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350057c2-a721-4a6d-bcca-7e7f146c1641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: maximum iterations reached --> 3\n",
      "Best Parameters from PSO: Hidden Units = 51, Learning Rate = 0.00010\n",
      "PSO Optimized Accuracy: 0.7469\n"
     ]
    }
   ],
   "source": [
    "# PSO-Optimized Neural Network\n",
    "\n",
    "# Objective function for PSO: minimize negative accuracy\n",
    "def objective_function(params):\n",
    "    hidden_units = int(params[0])\n",
    "    learning_rate = params[1]\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, input_dim=X_train.shape[1], activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=15, verbose=0, batch_size=32)\n",
    "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    return -acc  # PSO minimizes, so we negate accuracy\n",
    "\n",
    "# Search space: [hidden_units, learning_rate]\n",
    "lb = [10, 0.0001]\n",
    "ub = [100, 0.1]\n",
    "\n",
    "# Run PSO\n",
    "best_params, best_score = pso(objective_function, lb, ub, swarmsize=5, maxiter=3)\n",
    "print(f\"Best Parameters from PSO: Hidden Units = {int(best_params[0])}, Learning Rate = {best_params[1]:.5f}\")\n",
    "print(f\"PSO Optimized Accuracy: {-best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6d0ad1-2cbe-433d-a994-89cc609cd27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Comparison ---\n",
      "Manual Tuned Accuracy: 0.7406\n",
      "PSO Optimized Accuracy: 0.7469\n"
     ]
    }
   ],
   "source": [
    "# Final Comparison\n",
    "print(\"\\n--- Final Comparison ---\")\n",
    "print(f\"Manual Tuned Accuracy: {accuracy:.4f}\")\n",
    "print(f\"PSO Optimized Accuracy: {-best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73083439-854c-4fba-bec3-c7947ad2b056",
   "metadata": {},
   "source": [
    " Section\tB:\tTask\tDescription\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda2e0fc-2a7e-41d1-9a0f-5cb1440b139e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: keras in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: pyswarm in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\patel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install Required Packages\n",
    "!pip install scikit-learn keras pyswarm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98346fc4-6f0a-4260-92d4-1959d6bffa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Preprocess the Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load a small subset of the 20 newsgroups dataset for speed\n",
    "categories = ['rec.autos', 'sci.space', 'talk.politics.misc', 'comp.graphics']\n",
    "data = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Features and Labels\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Text vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=2000)  # Limit to 2000 features for speed\n",
    "X_vect = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y_enc, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e00606-f2e4-4b84-9276-72d4a774bb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.8617\n"
     ]
    }
   ],
   "source": [
    "# Build and Train Baseline Neural Network\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# One-hot encode labels for classification\n",
    "y_train_cat = to_categorical(y_train, num_classes=4)\n",
    "y_test_cat = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "# Function to build the model\n",
    "def build_nn(input_dim, hidden_units=64, lr=0.001):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train with default hyperparameters\n",
    "model = build_nn(X_train.shape[1], hidden_units=64, lr=0.001)\n",
    "model.fit(X_train, y_train_cat, epochs=5, batch_size=32, verbose=0)\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print(f\"Baseline Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e471e5eb-b8a8-49a6-8a18-56f82317b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: maximum iterations reached --> 3\n",
      "\n",
      "PSO Best Hidden Units: 123\n",
      "PSO Best Learning Rate: 0.00109\n",
      "PSO Optimized Accuracy: 0.8644\n"
     ]
    }
   ],
   "source": [
    "# PSO to Optimize Neural Network Hyperparameters\n",
    "from pyswarm import pso\n",
    "\n",
    "# Objective function for PSO\n",
    "def pso_objective(params):\n",
    "    hidden_units = int(params[0])\n",
    "    lr = params[1]\n",
    "\n",
    "    model = build_nn(X_train.shape[1], hidden_units=hidden_units, lr=lr)\n",
    "    model.fit(X_train, y_train_cat, epochs=3, batch_size=32, verbose=0)\n",
    "    loss, acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "    \n",
    "    return -acc  # PSO minimizes this\n",
    "\n",
    "# Define hyperparameter bounds: [hidden_units, learning_rate]\n",
    "lb = [16, 0.0001]\n",
    "ub = [128, 0.01]\n",
    "\n",
    "# Run PSO (small particles and iterations to keep runtime low)\n",
    "best_params, best_score = pso(pso_objective, lb, ub, swarmsize=5, maxiter=3)\n",
    "\n",
    "print(f\"\\nPSO Best Hidden Units: {int(best_params[0])}\")\n",
    "print(f\"PSO Best Learning Rate: {best_params[1]:.5f}\")\n",
    "print(f\"PSO Optimized Accuracy: {-best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea6107d-58e6-4396-abb7-b5920a6a1cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Comparison ---\n",
      "Traditional NN Accuracy: 0.8617\n",
      "PSO-Optimized NN Accuracy: 0.8644\n"
     ]
    }
   ],
   "source": [
    "# Final Comparison and Analysis\n",
    "print(\"\\n--- Final Comparison ---\")\n",
    "print(f\"Traditional NN Accuracy: {acc:.4f}\")\n",
    "print(f\"PSO-Optimized NN Accuracy: {-best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814868b-2b8a-4ca4-be43-a9177e737524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
